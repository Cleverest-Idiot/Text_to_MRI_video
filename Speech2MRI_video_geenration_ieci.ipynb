{"cells":[{"cell_type":"code","source":["# '''\n","# Written by Tamas Gabor Csapo <csapot@tmit.bme.hu>\n","# First version Jan 21, 2019\n","# Restructured Jan 21, 2020 - for MRI data\n","# Keras implementation of Csapó T.G., ,,Speaker dependent acoustic-to-articulatory inversion using real-time MRI of the vocal tract'', accepted at Interspeech 2020\n","# code for inference (MRI video generation)\n","# '''\n","\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# import scipy.io.wavfile as io_wav\n","# import os\n","# import os.path\n","# import glob\n","# import pickle\n","\n","# import cv2\n","# import numpy as np\n","# from cv2 import VideoWriter, VideoWriter_fourcc\n","\n","# from subprocess import call, check_output, run\n","\n","# # import vocoder_LSP_sptk\n","\n","# from keras.models import model_from_json\n","\n","# from keras.models import Sequential\n","# from keras.layers import Dense\n","# from keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n","# from keras.metrics import mean_squared_error\n","\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","# import subprocess\n","# from subprocess import run\n","# import numpy as np\n","# import scipy.io.wavfile as io_wav\n","\n","# # do not use all GPU memory\n","# import tensorflow as tf\n","# # from keras.backend import set_session\n","# import tensorflow\n","# from tensorflow.compat.v1.keras.backend import set_session\n","# import librosa\n","\n","\n","\n","# config = tf.compat.v1.ConfigProto()\n","# # config.gpu_options.per_process_gpu_memory_fraction = 0.3\n","# config.gpu_options.allow_growth = True\n","# set_session(tf.compat.v1.Session(config=config))\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io.wavfile as io_wav\n","import os\n","import glob\n","import pickle\n","import cv2\n","from cv2 import VideoWriter, VideoWriter_fourcc\n","import librosa\n","from keras.models import model_from_json\n","from keras import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n","from keras.metrics import MeanSquaredError\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, model_from_json\n","from tensorflow.keras.saving import register_keras_serializable\n","from tensorflow.keras import backend as K\n","import subprocess  # Add this import\n","from subprocess import run\n","\n","# Register the Sequential class if Keras fails to locate it\n","register_keras_serializable()(Sequential)\n","\n","# Limit GPU memory usage in TensorFlow 2.x\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        print(e)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# from LipReading with slight modifications\n","# https://github.com/hassanhub/LipReading/blob/master/codes/data_integration.py\n","################## VIDEO INPUT ##################\n","def load_video_3D(path, framesPerSec):\n","\n","    cap = cv2.VideoCapture(path)\n","    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT ))\n","    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH ))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    # make sure that all the videos are the same FPS\n","    if (np.abs(fps - framesPerSec) > 0.01):\n","        print('fps:', fps, '(' + path + ')')\n","        buf = np.empty((frameHeight, frameWidth, frameCount), np.dtype('float32'))\n","\n","    buf = np.empty((frameHeight, frameWidth, frameCount), np.dtype('float32'))\n","    fc = 0\n","    ret = True\n","\n","    while (fc < frameCount  and ret):\n","        ret, frame = cap.read()\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        frame = frame.astype('float32')\n","        # min-max scaling to [0-1]\n","        frame = frame-np.amin(frame)\n","        # make sure not to divide by zero\n","        if np.amax(frame) != 0:\n","            frame = frame/np.amax(frame)\n","        buf[:,:,fc]=frame\n","        fc += 1\n","    cap.release()\n","\n","    return buf\n","\n","# load vocoder features,\n","# or calculate, if they are not available\n","def get_mgc_lsp_coeff(basefilename):\n","    if os.path.isfile(basefilename + '.mgclsp'):\n","        mgc_lsp_coeff = np.fromfile(basefilename + '.mgclsp', dtype=np.float32).reshape(-1, order + 1)\n","        lf0 = np.fromfile(basefilename + '.lf0', dtype=np.float32)\n","    else:\n","        (mgc_lsp_coeff, lf0) = vocoder_LSP_sptk.encode(basefilename, samplingFrequency, frameLength, frameShift, order, alpha, stage)\n","    return (mgc_lsp_coeff, lf0)\n","\n","# convert an array of values into a dataset matrix\n","# code with modifications from\n","# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n","def create_dataset_img(data_in_X, data_in_Y, look_back=1):\n","    (dim1_X, dim2_X, dim3_X, dim4_X) = data_in_X.shape\n","    (dim1_Y, dim2_Y) = data_in_Y.shape\n","    data_out_X = np.empty((dim1_X - look_back - 1, look_back, dim2_X, dim3_X, dim4_X))\n","    data_out_Y = np.empty((dim1_Y - look_back - 1, dim2_Y))\n","\n","    for i in range(dim1_X - look_back - 1):\n","        for j in range(look_back):\n","            data_out_X[i, j] = data_in_X[i + j]\n","        data_out_Y[i] = data_in_Y[i + j]\n","    return data_out_X, data_out_Y\n","\n","# convert an array of values into a dataset matrix\n","# code with modifications from\n","# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n","def create_dataset_img_inverse(data_in_X, data_in_Y, look_back=1):\n","    (dim1_X, dim2_X) = data_in_X.shape\n","    (dim1_Y, dim2_Y, dim3_Y, dim4_Y) = data_in_Y.shape\n","    data_out_X = np.empty((dim1_X - look_back - 1, look_back, dim2_X))\n","    data_out_Y = np.empty((dim1_Y - look_back - 1, dim2_Y, dim3_Y, dim4_Y))\n","\n","    for i in range(dim1_X - look_back - 1):\n","        for j in range(look_back):\n","            data_out_X[i, j] = data_in_X[i + j]\n","        data_out_Y[i] = data_in_Y[i + j]\n","    return data_out_X, data_out_Y\n","\n","# mri2vid converts raw MRI data to .mp4 video\n","def mri2vid(mri_data, dir_file, filename_no_ext, n_width, n_height, FramesPerSec):\n","\n","    print(filename_no_ext + ' - MRI video started')\n","\n","    output_file_no_ext = dir_file + filename_no_ext\n","    n_frames = len(mri_data)\n","\n","    # compressed\n","    # fourcc = VideoWriter_fourcc(*'MP4V')\n","\n","    # uncompressed 8-bit\n","    fourcc = VideoWriter_fourcc(*'Y800')\n","    video = VideoWriter(output_file_no_ext + '.avi', fourcc, float(FramesPerSec), (n_width, n_height), 0)\n","\n","    for n in range(n_frames):\n","        frame = np.uint8(255 * mri_data[n]).reshape(n_width, n_height, 1)\n","\n","        video.write(frame)\n","        print('frame ', n, ' done', end='\\r')\n","\n","    video.release()\n","\n","    print(filename_no_ext + ' - MRI video finished')\n","\n","def mrividwav2demo(dir_mri, file_mri, dir_wav, file_wav):\n","    # \"-codec copy \" + \\\n","    command = \"ffmpeg \" + \\\n","           \"-y \" + \\\n","           \"-i \" + dir_mri + file_mri + \" \" + \\\n","           \"-i \" + dir_wav + file_wav + \" \" + \\\n","           \"-shortest \" + \\\n","           \"-acodec copy -vcodec copy \" + \\\n","            dir_mri + file_mri[:-4] + \"_with_audio.avi\"\n","           # \"-c:v h264 -crf 20 -c:a aac -strict -2 \" + \\\n","           # \"-filter:v \\\"crop=820:496:215:48\\\" \" + \\\n","\n","    print(command)\n","    run(command, shell=True)\n","\n","\n","\n","# speakerlist = ['F1']\n","# model_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/models/Models_for_Text2MRI/'\n","# # output_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/generated_image_sequence/'\n","# output_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/generated_image_sequence_original_audio/'\n","\n","\n","# # Input_audio_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/audio_files_for_input/'\n","# Input_audio_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/original_audio_files/'\n","\n","\n","\n","speakerlist = ['F1', 'F2', 'M2', 'M3']\n","model_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/models_speech2mri_2024/'\n","# output_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/testing_models/'\n","output_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/'\n","\n","# Input_audio_path = '/content/drive/MyDrive/GAN_based_models/wav_files/'\n","# Input_audio_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/original_audio_files/'\n","Input_audio_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/'\n","\n","\n","speakerInd = 0\n","# for speaker in ['f1']: # ['f1', 'f2', 'm1', 'm2']:\n","for speaker in speakerlist:\n","    # TODO: modify this according to your data path\n","    # dir_mri = '/content/drive/MyDrive/backup_PhD/database/MRI_USC/data/' + speaker + '/avi/'\n","    # dir_mri_test = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/' + speaker + '/'\n","    dir_mri_test = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/' + speaker + '/'\n","\n","\n","    if not os.path.exists(dir_mri_test):\n","        os.makedirs(dir_mri_test)\n","\n","    # Parameters of vocoder\n","    samplingFrequency = 20000\n","    frameLength = 1024 #\n","    frameShift = 863 # 43.14 ms at 20000 Hz sampling, correspondong to 23.18 fps (MRI video)\n","    order = 24\n","    alpha = 0.42\n","    stage = 3\n","    n_mgc = order + 1\n","\n","    # context window of LSTM\n","    n_sequence = 10\n","\n","    # properties of MRI videos\n","    framesPerSec = 23.18\n","    n_width = 68\n","    n_height = 68\n","\n","    # modelbasenames = [ 'SPEECH2MRI_LSTM_baseline_Text2MRI_M2_2023-04-18_10-55-58',\n","    #           'SPEECH2MRI_LSTM_baseline_Text2MRI_M3_2023-04-18_12-28-25',\n","    #           'SPEECH2MRI_LSTM_baseline_Text2MRI_F1_2023-04-18_13-44-16',\n","    #           'SPEECH2MRI_LSTM_baseline_F2_2024-10-04_10-04-46']\n","\n","    modelbasenames = [ 'SPEECH2MRI_LSTM_baseline_F1_2024-10-04_09-57-40',\n","                      'SPEECH2MRI_LSTM_baseline_F2_2024-10-04_10-04-46',\n","                       'SPEECH2MRI_LSTM_baseline_M2_2024-10-04_09-33-21',\n","                       'SPEECH2MRI_LSTM_baseline_M3_2024-10-04_09-52-15']\n","\n","    # modelbasenames = [ 'SPEECH2MRI_Transformer_baseline_F1_2024-10-27_07-42-48',\n","    #                   'SPEECH2MRI_Transformer_baseline_F2_2024-10-27_07-46-43',\n","    #                    'SPEECH2MRI_Transformer_baseline_M2_2024-10-27_07-36-15',\n","    #                    'SPEECH2MRI_Transformer_baseline_M3_2024-10-27_07-40-11']\n","\n","\n","    # DNN_types = ['FC-DNN_baseline', 'CNN', 'LSTM']\n","    #DNN_types = ['FC-DNN_baseline']\n","    # DNN_types = ['LSTM-CNN']\n","    DNN_types = ['LSTM']\n","    # DNN_types = ['Transformer']\n","    # basefilenames_mri_test = ['usctimit_mri_' + speaker.lower() + '_146_150', 'usctimit_mri_' + speaker.lower() + '_441_445']\n","    basefilenames_mri_test = glob.glob(Input_audio_path + speaker +'/*.wav')\n","\n","    for DNN_type in DNN_types:\n","        # e.g. MRI2SPEECH_CNN_f1_2020-01-16_10-36-35\n","        # csv_files = glob.glob('/content/drive/MyDrive/GAN_based_models/speech2mri/models/SPEECH2MRI_' + DNN_type + '_baseline_Text2MRI_' + speaker + '*.csv')\n","        csv_files = glob.glob(model_path + modelbasenames[speakerInd] +'*.csv')\n","        model_name = csv_files[-1][:-4]\n","\n","        speakerInd = speakerInd + 1\n","        # load model\n","        print('loading model', model_name)\n","        with open(model_name + '_model.json', \"r\") as json_file:\n","            loaded_model_json = json_file.read()\n","        # model = model_from_json(loaded_model_json)\n","\n","        model = model_from_json(loaded_model_json, custom_objects={'Sequential': Sequential})\n","        model.load_weights(model_name + '_weights.keras')\n","        print(\"Loaded model from disk\")\n","        # load weights into new model\n","        # model.load_weights(model_name + '_weights.h5')\n","        # load scalers\n","        mgc_scalers = pickle.load(open(model_name + '_mgc_scalers.sav', 'rb'))\n","\n","        for basefilename in basefilenames_mri_test:\n","            print('Predicting output for: ', basefilename)\n","\n","            # load data for sentence\n","            # mri_data = load_video_3D(dir_mri + basefilename + '.avi', framesPerSec)\n","            # mri_len = mri_data.shape[2]\n","            # mri_test = np.empty((mri_len, n_width, n_height))\n","            # (mgc_lsp_coeff, lf0) = get_mgc_lsp_coeff(dir_mri + basefilename)\n","            # dir_mri_wav_only = dir_mri.replace('/avi/','/wav/')\n","            # dir_mri_wav = dir_mri_wav_only + basefilename+'.wav'\n","            dir_mri_wav = basefilename\n","            basefilename_name_only = basefilename.split('/')\n","            basefilename_name_only = basefilename_name_only[-1]\n","            basefilename_name_only = basefilename_name_only.replace('.wav', '')\n","\n","            print(basefilename_name_only)\n","            x, sr = librosa.load(dir_mri_wav, sr = samplingFrequency)\n","            n_fft = frameLength   # window length: 0.02 s\n","            hop_length = frameShift  #\n","            mgc_lsp_coeff = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=25, hop_length=hop_length, n_fft=n_fft)\n","            mgc_lsp_coeff = mgc_lsp_coeff.transpose()\n","\n","\n","\n","            # for i in range(mri_len):\n","            #     mri_test[i] = mri_data[:, :, i] # original, 68x68\n","\n","            # transform of input parameters\n","            for i in range(n_mgc):\n","                mgc_lsp_coeff[:, i] = mgc_scalers[i].transform(mgc_lsp_coeff[:, i].reshape(-1, 1)).ravel()\n","\n","            # reshape for LSTM\n","            if DNN_type == 'LSTM' or DNN_type == 'LSTM-CNN' or DNN_type == 'Transformer':\n","                mgc_len = len(mgc_lsp_coeff)\n","                mri0 = np.empty((mgc_len, n_width, n_height, 1))\n","\n","                mgc_test0, mri0 = create_dataset_img_inverse(mgc_lsp_coeff, mri0, look_back = n_sequence)\n","                mri0 = mri0.reshape(-1, n_width * n_height)\n","                mgc_test = np.empty((mgc_len, n_sequence, n_mgc))\n","\n","                # # add first n_sequence values\n","                # for i in range(mgc_len - 2):\n","                #     if i < n_sequence - 0:\n","                #         mgc_test[i] = mgc_test0[0]\n","                #     else:\n","                #         mgc_test[i] = mgc_test0[i - n_sequence + 1]\n","\n","                # mgc_lsp_coeff = mgc_test\n","\n","            mgc_lsp_coeff = mgc_test0\n","            # predict MR image sequence using the trained model\n","            mri_predicted = model.predict(mgc_lsp_coeff)\n","            print('Prediction done')\n","            # clip extreme values\n","            mri_predicted = np.clip(mri_predicted, 0, 1)\n","\n","            print(mri_predicted.shape)\n","\n","            y_pred = mri_predicted\n","            y_true = mri0\n","\n","            # # Calculating the error\n","            # FrameErr = np.zeros((y_true.shape[0],1))\n","            # for i in range(y_true.shape[0]):\n","            #   t1 = y_pred[i,:]\n","            #   t2 = y_true[i,:]\n","            #   terr =np.mean((np.square(t1-t2)))\n","            #   FrameErr[i]=terr\n","\n","            # MSErr = np.mean(FrameErr)\n","            # print(MSErr)\n","\n","            # MSErr_fn = mean_squared_error(y_pred, y_true)\n","            # print(np.mean(MSErr_fn))\n","\n","\n","            # save image sequence to video (without audio)\n","            mri2vid(mri_predicted, dir_mri_test, basefilename_name_only + '_' + DNN_type, n_width, n_height, framesPerSec)\n","\n","            dir_mri_wav_only = Input_audio_path + speaker +'/'\n","            # put together video and audio\n","            mrividwav2demo(dir_mri_test, basefilename_name_only + '_' + DNN_type + '.avi', \\\n","                dir_mri_wav_only, basefilename_name_only + '.wav')\n","\n","\n"],"metadata":{"id":"iLOtDE_owIsa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730270067683,"user_tz":-330,"elapsed":211062,"user":{"displayName":"Nataraj K","userId":"01169114469723500270"}},"outputId":"7eaa6d74-15fe-4717-fd53-d5d3b9015dc9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["loading model /content/drive/MyDrive/GAN_based_models/speech2mri/models_speech2mri_2024/SPEECH2MRI_LSTM_baseline_F1_2024-10-04_09-57-40\n","Loaded model from disk\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_441_445.wav\n","usctimit_mri_f1_441_445\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step\n","Prediction done\n","(591, 4624)\n","usctimit_mri_f1_441_445_LSTM - MRI video started\n","usctimit_mri_f1_441_445_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_441_445_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_441_445.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_441_445_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_146_150.wav\n","usctimit_mri_f1_146_150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n","Prediction done\n","(616, 4624)\n","usctimit_mri_f1_146_150_LSTM - MRI video started\n","usctimit_mri_f1_146_150_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_146_150_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_146_150.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_146_150_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_261_265.wav\n","usctimit_mri_f1_261_265\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Prediction done\n","(655, 4624)\n","usctimit_mri_f1_261_265_LSTM - MRI video started\n","usctimit_mri_f1_261_265_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_261_265_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_261_265.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_261_265_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_121_125.wav\n","usctimit_mri_f1_121_125\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Prediction done\n","(648, 4624)\n","usctimit_mri_f1_121_125_LSTM - MRI video started\n","usctimit_mri_f1_121_125_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_121_125_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_121_125.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_121_125_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_316_320.wav\n","usctimit_mri_f1_316_320\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n","Prediction done\n","(775, 4624)\n","usctimit_mri_f1_316_320_LSTM - MRI video started\n","usctimit_mri_f1_316_320_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_316_320_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_316_320.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_316_320_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_411_415.wav\n","usctimit_mri_f1_411_415\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n","Prediction done\n","(502, 4624)\n","usctimit_mri_f1_411_415_LSTM - MRI video started\n","usctimit_mri_f1_411_415_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_411_415_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_411_415.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_411_415_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_101_105.wav\n","usctimit_mri_f1_101_105\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n","Prediction done\n","(518, 4624)\n","usctimit_mri_f1_101_105_LSTM - MRI video started\n","usctimit_mri_f1_101_105_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_101_105_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_101_105.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_101_105_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_061_065.wav\n","usctimit_mri_f1_061_065\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n","Prediction done\n","(540, 4624)\n","usctimit_mri_f1_061_065_LSTM - MRI video started\n","usctimit_mri_f1_061_065_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_061_065_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_061_065.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_061_065_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_091_095.wav\n","usctimit_mri_f1_091_095\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n","Prediction done\n","(565, 4624)\n","usctimit_mri_f1_091_095_LSTM - MRI video started\n","usctimit_mri_f1_091_095_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_091_095_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_091_095.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_091_095_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_396_400.wav\n","usctimit_mri_f1_396_400\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n","Prediction done\n","(642, 4624)\n","usctimit_mri_f1_396_400_LSTM - MRI video started\n","usctimit_mri_f1_396_400_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_396_400_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F1/usctimit_mri_f1_396_400.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F1/usctimit_mri_f1_396_400_LSTM_with_audio.avi\n","loading model /content/drive/MyDrive/GAN_based_models/speech2mri/models_speech2mri_2024/SPEECH2MRI_LSTM_baseline_F2_2024-10-04_10-04-46\n","Loaded model from disk\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_441_445.wav\n","usctimit_mri_f2_441_445\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step\n","Prediction done\n","(585, 4624)\n","usctimit_mri_f2_441_445_LSTM - MRI video started\n","usctimit_mri_f2_441_445_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_441_445_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_441_445.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_441_445_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_146_150.wav\n","usctimit_mri_f2_146_150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n","Prediction done\n","(626, 4624)\n","usctimit_mri_f2_146_150_LSTM - MRI video started\n","usctimit_mri_f2_146_150_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_146_150_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_146_150.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_146_150_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_261_265.wav\n","usctimit_mri_f2_261_265\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n","Prediction done\n","(650, 4624)\n","usctimit_mri_f2_261_265_LSTM - MRI video started\n","usctimit_mri_f2_261_265_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_261_265_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_261_265.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_261_265_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_121_125.wav\n","usctimit_mri_f2_121_125\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n","Prediction done\n","(638, 4624)\n","usctimit_mri_f2_121_125_LSTM - MRI video started\n","usctimit_mri_f2_121_125_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_121_125_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_121_125.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_121_125_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_316_320.wav\n","usctimit_mri_f2_316_320\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n","Prediction done\n","(774, 4624)\n","usctimit_mri_f2_316_320_LSTM - MRI video started\n","usctimit_mri_f2_316_320_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_316_320_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_316_320.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_316_320_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_411_415.wav\n","usctimit_mri_f2_411_415\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n","Prediction done\n","(493, 4624)\n","usctimit_mri_f2_411_415_LSTM - MRI video started\n","usctimit_mri_f2_411_415_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_411_415_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_411_415.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_411_415_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_101_105.wav\n","usctimit_mri_f2_101_105\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n","Prediction done\n","(524, 4624)\n","usctimit_mri_f2_101_105_LSTM - MRI video started\n","usctimit_mri_f2_101_105_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_101_105_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_101_105.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_101_105_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_061_065.wav\n","usctimit_mri_f2_061_065\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step\n","Prediction done\n","(539, 4624)\n","usctimit_mri_f2_061_065_LSTM - MRI video started\n","usctimit_mri_f2_061_065_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_061_065_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_061_065.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_061_065_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_091_095.wav\n","usctimit_mri_f2_091_095\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Prediction done\n","(574, 4624)\n","usctimit_mri_f2_091_095_LSTM - MRI video started\n","usctimit_mri_f2_091_095_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_091_095_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_091_095.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_091_095_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_396_400.wav\n","usctimit_mri_f2_396_400\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n","Prediction done\n","(604, 4624)\n","usctimit_mri_f2_396_400_LSTM - MRI video started\n","usctimit_mri_f2_396_400_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_396_400_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/F2/usctimit_mri_f2_396_400.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/F2/usctimit_mri_f2_396_400_LSTM_with_audio.avi\n","loading model /content/drive/MyDrive/GAN_based_models/speech2mri/models_speech2mri_2024/SPEECH2MRI_LSTM_baseline_M2_2024-10-04_09-33-21\n","Loaded model from disk\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_441_445.wav\n","usctimit_mri_m2_441_445\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step\n","Prediction done\n","(591, 4624)\n","usctimit_mri_m2_441_445_LSTM - MRI video started\n","usctimit_mri_m2_441_445_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_441_445_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_441_445.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_441_445_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_146_150.wav\n","usctimit_mri_m2_146_150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n","Prediction done\n","(610, 4624)\n","usctimit_mri_m2_146_150_LSTM - MRI video started\n","usctimit_mri_m2_146_150_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_146_150_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_146_150.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_146_150_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_261_265.wav\n","usctimit_mri_m2_261_265\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n","Prediction done\n","(646, 4624)\n","usctimit_mri_m2_261_265_LSTM - MRI video started\n","usctimit_mri_m2_261_265_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_261_265_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_261_265.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_261_265_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_121_125.wav\n","usctimit_mri_m2_121_125\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Prediction done\n","(640, 4624)\n","usctimit_mri_m2_121_125_LSTM - MRI video started\n","usctimit_mri_m2_121_125_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_121_125_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_121_125.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_121_125_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_316_320.wav\n","usctimit_mri_m2_316_320\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n","Prediction done\n","(775, 4624)\n","usctimit_mri_m2_316_320_LSTM - MRI video started\n","usctimit_mri_m2_316_320_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_316_320_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_316_320.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_316_320_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_411_415.wav\n","usctimit_mri_m2_411_415\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step\n","Prediction done\n","(513, 4624)\n","usctimit_mri_m2_411_415_LSTM - MRI video started\n","usctimit_mri_m2_411_415_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_411_415_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_411_415.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_411_415_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_101_105.wav\n","usctimit_mri_m2_101_105\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n","Prediction done\n","(517, 4624)\n","usctimit_mri_m2_101_105_LSTM - MRI video started\n","usctimit_mri_m2_101_105_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_101_105_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_101_105.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_101_105_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_061_065.wav\n","usctimit_mri_m2_061_065\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n","Prediction done\n","(553, 4624)\n","usctimit_mri_m2_061_065_LSTM - MRI video started\n","usctimit_mri_m2_061_065_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_061_065_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_061_065.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_061_065_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_091_095.wav\n","usctimit_mri_m2_091_095\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step\n","Prediction done\n","(566, 4624)\n","usctimit_mri_m2_091_095_LSTM - MRI video started\n","usctimit_mri_m2_091_095_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_091_095_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_091_095.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_091_095_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_396_400.wav\n","usctimit_mri_m2_396_400\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step\n","Prediction done\n","(606, 4624)\n","usctimit_mri_m2_396_400_LSTM - MRI video started\n","usctimit_mri_m2_396_400_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_396_400_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M2/usctimit_mri_m2_396_400.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M2/usctimit_mri_m2_396_400_LSTM_with_audio.avi\n","loading model /content/drive/MyDrive/GAN_based_models/speech2mri/models_speech2mri_2024/SPEECH2MRI_LSTM_baseline_M3_2024-10-04_09-52-15\n","Loaded model from disk\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_441_445.wav\n","usctimit_mri_m3_441_445\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step\n","Prediction done\n","(533, 4624)\n","usctimit_mri_m3_441_445_LSTM - MRI video started\n","usctimit_mri_m3_441_445_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_441_445_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_441_445.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_441_445_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_146_150.wav\n","usctimit_mri_m3_146_150\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step\n","Prediction done\n","(536, 4624)\n","usctimit_mri_m3_146_150_LSTM - MRI video started\n","usctimit_mri_m3_146_150_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_146_150_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_146_150.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_146_150_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_261_265.wav\n","usctimit_mri_m3_261_265\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Prediction done\n","(576, 4624)\n","usctimit_mri_m3_261_265_LSTM - MRI video started\n","usctimit_mri_m3_261_265_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_261_265_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_261_265.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_261_265_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_121_125.wav\n","usctimit_mri_m3_121_125\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Prediction done\n","(565, 4624)\n","usctimit_mri_m3_121_125_LSTM - MRI video started\n","usctimit_mri_m3_121_125_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_121_125_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_121_125.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_121_125_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_316_320.wav\n","usctimit_mri_m3_316_320\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n","Prediction done\n","(721, 4624)\n","usctimit_mri_m3_316_320_LSTM - MRI video started\n","usctimit_mri_m3_316_320_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_316_320_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_316_320.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_316_320_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_416_420.wav\n","usctimit_mri_m3_416_420\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n","Prediction done\n","(431, 4624)\n","usctimit_mri_m3_416_420_LSTM - MRI video started\n","usctimit_mri_m3_416_420_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_416_420_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_416_420.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_416_420_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_101_105.wav\n","usctimit_mri_m3_101_105\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Prediction done\n","(480, 4624)\n","usctimit_mri_m3_101_105_LSTM - MRI video started\n","usctimit_mri_m3_101_105_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_101_105_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_101_105.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_101_105_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_061_065.wav\n","usctimit_mri_m3_061_065\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n","Prediction done\n","(483, 4624)\n","usctimit_mri_m3_061_065_LSTM - MRI video started\n","usctimit_mri_m3_061_065_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_061_065_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_061_065.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_061_065_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_091_095.wav\n","usctimit_mri_m3_091_095\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Prediction done\n","(497, 4624)\n","usctimit_mri_m3_091_095_LSTM - MRI video started\n","usctimit_mri_m3_091_095_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_091_095_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_091_095.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_091_095_LSTM_with_audio.avi\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_401_405.wav\n","usctimit_mri_m3_401_405\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n","Prediction done\n","(540, 4624)\n","usctimit_mri_m3_401_405_LSTM - MRI video started\n","usctimit_mri_m3_401_405_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_401_405_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_audio_files/M3/usctimit_mri_m3_401_405.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/M3/usctimit_mri_m3_401_405_LSTM_with_audio.avi\n"]}]},{"cell_type":"code","source":["\n","import subprocess\n","from subprocess import run\n","mrividwav2demo(dir_mri_test, basefilename_name_only + '_' + DNN_type + '.avi', \\\n","                dir_mri_wav_only, basefilename_name_only + '.wav')\n"],"metadata":{"id":"kyYzI0LtAUj8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728044866088,"user_tz":-330,"elapsed":848,"user":{"displayName":"Nataraj K","userId":"01169114469723500270"}},"outputId":"a15d52dc-67eb-45b5-8f05-50d7e56a57e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/F1/usctimit_mri_f1_441_445_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/original_audio_files/F1/usctimit_mri_f1_441_445.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/F1/usctimit_mri_f1_441_445_LSTM_with_audio.avi\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from skimage.metrics import structural_similarity as ssim\n","\n","def calculate_video_ssim(video_path1, video_path2):\n","    cap1 = cv2.VideoCapture(video_path1)\n","    cap2 = cv2.VideoCapture(video_path2)\n","    ssim_values = []\n","\n","    while True:\n","        ret1, frame1 = cap1.read()\n","        ret2, frame2 = cap2.read()\n","\n","        if not ret1 or not ret2:\n","            break\n","\n","        gray_frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n","        gray_frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n","\n","        ssim_value, _ = ssim(gray_frame1, gray_frame2, full=True)\n","        ssim_values.append(ssim_value)\n","\n","    cap1.release()\n","    cap2.release()\n","    return np.mean(ssim_values), np.std(ssim_values)\n","\n","# Define paths to the main directories for folder1 and folder2\n","main_folder2 = '/content/drive/MyDrive/backup_PhD/database/MRI_USC/data/'\n","main_folder1 = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/'\n","\n","# Dictionary to store SSIM results for each speaker\n","overall_ssim_results = {}\n","\n","# Loop over each speaker directory in folder1\n","for speaker_folder in os.listdir(main_folder1):\n","    speaker_path1 = os.path.join(main_folder1, speaker_folder)\n","    speaker_path2 = os.path.join(main_folder2, speaker_folder, 'avi')\n","\n","    # Skip if it's not a directory or if there's no matching speaker folder in folder2\n","    if not os.path.isdir(speaker_path1) or not os.path.exists(speaker_path2):\n","        continue\n","\n","    ssim_results = []\n","\n","    # Loop over each file in the speaker's folder\n","    for file_name in os.listdir(speaker_path1):\n","        if not file_name.endswith(\"Transformer.avi\") and (not file_name.endswith(\"LSTM.avi\")):\n","            continue\n","\n","        video_path1 = os.path.join(speaker_path1, file_name)\n","        dest_file_name  = file_name.replace('_Transformer', '')\n","        video_path2 = os.path.join(speaker_path2, dest_file_name)\n","\n","        # Check if the file exists in both folders\n","        if os.path.exists(video_path2):\n","            mean_ssim, std_ssim = calculate_video_ssim(video_path1, video_path2)\n","            ssim_results.append(mean_ssim)\n","            print(f\"Speaker: {speaker_folder} - File: {file_name} - Mean SSIM: {mean_ssim:.4f}, Std SSIM: {std_ssim:.4f}\")\n","        else:\n","            print(f\"File {file_name} not found in both folders for Speaker {speaker_folder}.\")\n","\n","    # Calculate mean and standard deviation of SSIM for each speaker\n","    overall_ssim_results[speaker_folder] = {\n","        'mean_ssim': np.mean(ssim_results),\n","        'std_ssim': np.std(ssim_results)\n","    }\n","\n","# Print overall results for each speaker\n","print(\"\\nOverall SSIM Results for Each Speaker:\")\n","for speaker, results in overall_ssim_results.items():\n","    print(f\"{speaker} - Mean SSIM: {results['mean_ssim']:.4f}, Std SSIM: {results['std_ssim']:.4f}\")\n"],"metadata":{"id":"yL3arNjNf3D1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730270307365,"user_tz":-330,"elapsed":5,"user":{"displayName":"Nataraj K","userId":"01169114469723500270"}},"outputId":"ecba9d02-6e43-48cf-cd61-522f1d3745f8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["File usctimit_mri_f1_441_445_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f1_146_150_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f1_261_265_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f1_121_125_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f1_316_320_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f1_411_415_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f1_101_105_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f1_061_065_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f1_091_095_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f1_396_400_LSTM.avi not found in both folders for Speaker F1.\n","File usctimit_mri_f2_441_445_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_f2_146_150_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_f2_261_265_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_f2_121_125_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_f2_316_320_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_f2_411_415_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_f2_101_105_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_f2_061_065_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_f2_091_095_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_f2_396_400_LSTM.avi not found in both folders for Speaker F2.\n","File usctimit_mri_m2_441_445_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m2_146_150_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m2_261_265_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m2_121_125_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m2_316_320_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m2_411_415_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m2_101_105_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m2_061_065_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m2_091_095_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m2_396_400_LSTM.avi not found in both folders for Speaker M2.\n","File usctimit_mri_m3_441_445_LSTM.avi not found in both folders for Speaker M3.\n","File usctimit_mri_m3_146_150_LSTM.avi not found in both folders for Speaker M3.\n","File usctimit_mri_m3_261_265_LSTM.avi not found in both folders for Speaker M3.\n","File usctimit_mri_m3_121_125_LSTM.avi not found in both folders for Speaker M3.\n","File usctimit_mri_m3_316_320_LSTM.avi not found in both folders for Speaker M3.\n","File usctimit_mri_m3_416_420_LSTM.avi not found in both folders for Speaker M3.\n","File usctimit_mri_m3_101_105_LSTM.avi not found in both folders for Speaker M3.\n","File usctimit_mri_m3_061_065_LSTM.avi not found in both folders for Speaker M3.\n","File usctimit_mri_m3_091_095_LSTM.avi not found in both folders for Speaker M3.\n","File usctimit_mri_m3_401_405_LSTM.avi not found in both folders for Speaker M3.\n","\n","Overall SSIM Results for Each Speaker:\n","F1 - Mean SSIM: nan, Std SSIM: nan\n","F2 - Mean SSIM: nan, Std SSIM: nan\n","M2 - Mean SSIM: nan, Std SSIM: nan\n","M3 - Mean SSIM: nan, Std SSIM: nan\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n","  return _methods._mean(a, axis=axis, dtype=dtype,\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n","  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n","  arrmean = um.true_divide(arrmean, div, out=arrmean,\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n","  ret = ret.dtype.type(ret / rcount)\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from skimage.metrics import structural_similarity as ssim\n","\n","def calculate_video_ssim(video_path1, video_path2):\n","    cap1 = cv2.VideoCapture(video_path1)\n","    cap2 = cv2.VideoCapture(video_path2)\n","    ssim_values = []\n","\n","    while True:\n","        ret1, frame1 = cap1.read()\n","        ret2, frame2 = cap2.read()\n","\n","        if not ret1 or not ret2:\n","            break\n","\n","        gray_frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n","        gray_frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n","\n","        ssim_value, _ = ssim(gray_frame1, gray_frame2, full=True)\n","        ssim_values.append(ssim_value)\n","\n","    cap1.release()\n","    cap2.release()\n","    return np.mean(ssim_values), np.std(ssim_values)\n","\n","# Define paths to the main directories for folder1 and folder2\n","main_folder2 = '/content/drive/MyDrive/backup_PhD/database/MRI_USC/data/'\n","main_folder1 = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/test_video_generated/LSTM_10_outputs/'\n","\n","# Dictionary to store SSIM results for each speaker\n","overall_ssim_results = {}\n","\n","# Loop over each speaker directory in folder1\n","for speaker_folder in os.listdir(main_folder1):\n","    speaker_path1 = os.path.join(main_folder1, speaker_folder)\n","    speaker_path2 = os.path.join(main_folder2, speaker_folder, 'avi')\n","\n","    # Skip if it's not a directory or if there's no matching speaker folder in folder2\n","    if not os.path.isdir(speaker_path1) or not os.path.exists(speaker_path2):\n","        continue\n","\n","    ssim_results = []\n","\n","    # Loop over each file in the speaker's folder\n","    for file_name in os.listdir(speaker_path1):\n","        if not file_name.endswith(\"LSTM.avi\"):\n","            continue\n","\n","        video_path1 = os.path.join(speaker_path1, file_name)\n","        dest_file_name  = file_name.replace('_LSTM', '')\n","        video_path2 = os.path.join(speaker_path2, dest_file_name)\n","\n","        # Check if the file exists in both folders\n","        if os.path.exists(video_path2):\n","            mean_ssim, std_ssim = calculate_video_ssim(video_path1, video_path2)\n","            ssim_results.append(mean_ssim)\n","            print(f\"Speaker: {speaker_folder} - File: {file_name} - Mean SSIM: {mean_ssim:.4f}, Std SSIM: {std_ssim:.4f}\")\n","        else:\n","            print(video_path2)\n","            print(f\"File {file_name} not found in both folders for Speaker {speaker_folder}.\")\n","\n","    # Calculate mean and standard deviation of SSIM for each speaker\n","    overall_ssim_results[speaker_folder] = {\n","        'mean_ssim': np.mean(ssim_results),\n","        'std_ssim': np.std(ssim_results)\n","    }\n","\n","# Print overall results for each speaker\n","print(\"\\nOverall SSIM Results for Each Speaker:\")\n","for speaker, results in overall_ssim_results.items():\n","    print(f\"{speaker} - Mean SSIM: {results['mean_ssim']:.4f}, Std SSIM: {results['std_ssim']:.4f}\")\n"],"metadata":{"id":"OcfGiqsAflWs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730270669406,"user_tz":-330,"elapsed":51992,"user":{"displayName":"Nataraj K","userId":"01169114469723500270"}},"outputId":"b7ea8301-366a-4d40-d30d-03713f77ed83"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Speaker: F1 - File: usctimit_mri_f1_441_445_LSTM.avi - Mean SSIM: 0.7689, Std SSIM: 0.0738\n","Speaker: F1 - File: usctimit_mri_f1_146_150_LSTM.avi - Mean SSIM: 0.7995, Std SSIM: 0.0564\n","Speaker: F1 - File: usctimit_mri_f1_261_265_LSTM.avi - Mean SSIM: 0.8193, Std SSIM: 0.0616\n","Speaker: F1 - File: usctimit_mri_f1_121_125_LSTM.avi - Mean SSIM: 0.8155, Std SSIM: 0.0495\n","Speaker: F1 - File: usctimit_mri_f1_316_320_LSTM.avi - Mean SSIM: 0.7812, Std SSIM: 0.0494\n","Speaker: F1 - File: usctimit_mri_f1_411_415_LSTM.avi - Mean SSIM: 0.7566, Std SSIM: 0.0862\n","Speaker: F1 - File: usctimit_mri_f1_101_105_LSTM.avi - Mean SSIM: 0.8135, Std SSIM: 0.0626\n","Speaker: F1 - File: usctimit_mri_f1_061_065_LSTM.avi - Mean SSIM: 0.8204, Std SSIM: 0.0590\n","Speaker: F1 - File: usctimit_mri_f1_091_095_LSTM.avi - Mean SSIM: 0.8201, Std SSIM: 0.0612\n","Speaker: F1 - File: usctimit_mri_f1_396_400_LSTM.avi - Mean SSIM: 0.8053, Std SSIM: 0.0625\n","Speaker: F2 - File: usctimit_mri_f2_441_445_LSTM.avi - Mean SSIM: 0.7067, Std SSIM: 0.0644\n","Speaker: F2 - File: usctimit_mri_f2_146_150_LSTM.avi - Mean SSIM: 0.7095, Std SSIM: 0.0612\n","Speaker: F2 - File: usctimit_mri_f2_261_265_LSTM.avi - Mean SSIM: 0.7233, Std SSIM: 0.0710\n","Speaker: F2 - File: usctimit_mri_f2_121_125_LSTM.avi - Mean SSIM: 0.7260, Std SSIM: 0.0518\n","Speaker: F2 - File: usctimit_mri_f2_316_320_LSTM.avi - Mean SSIM: 0.7380, Std SSIM: 0.0561\n","Speaker: F2 - File: usctimit_mri_f2_411_415_LSTM.avi - Mean SSIM: 0.6988, Std SSIM: 0.0747\n","Speaker: F2 - File: usctimit_mri_f2_101_105_LSTM.avi - Mean SSIM: 0.7410, Std SSIM: 0.0647\n","Speaker: F2 - File: usctimit_mri_f2_061_065_LSTM.avi - Mean SSIM: 0.7406, Std SSIM: 0.0881\n","Speaker: F2 - File: usctimit_mri_f2_091_095_LSTM.avi - Mean SSIM: 0.6956, Std SSIM: 0.0721\n","Speaker: F2 - File: usctimit_mri_f2_396_400_LSTM.avi - Mean SSIM: 0.7205, Std SSIM: 0.0643\n","Speaker: M2 - File: usctimit_mri_m2_441_445_LSTM.avi - Mean SSIM: 0.7828, Std SSIM: 0.0500\n","Speaker: M2 - File: usctimit_mri_m2_146_150_LSTM.avi - Mean SSIM: 0.7622, Std SSIM: 0.0698\n","Speaker: M2 - File: usctimit_mri_m2_261_265_LSTM.avi - Mean SSIM: 0.7639, Std SSIM: 0.0694\n","Speaker: M2 - File: usctimit_mri_m2_121_125_LSTM.avi - Mean SSIM: 0.7651, Std SSIM: 0.0676\n","Speaker: M2 - File: usctimit_mri_m2_316_320_LSTM.avi - Mean SSIM: 0.7918, Std SSIM: 0.0430\n","Speaker: M2 - File: usctimit_mri_m2_411_415_LSTM.avi - Mean SSIM: 0.7018, Std SSIM: 0.0771\n","Speaker: M2 - File: usctimit_mri_m2_101_105_LSTM.avi - Mean SSIM: 0.7675, Std SSIM: 0.0639\n","Speaker: M2 - File: usctimit_mri_m2_061_065_LSTM.avi - Mean SSIM: 0.7706, Std SSIM: 0.0655\n","Speaker: M2 - File: usctimit_mri_m2_091_095_LSTM.avi - Mean SSIM: 0.7706, Std SSIM: 0.0635\n","Speaker: M2 - File: usctimit_mri_m2_396_400_LSTM.avi - Mean SSIM: 0.7774, Std SSIM: 0.0480\n","Speaker: M3 - File: usctimit_mri_m3_441_445_LSTM.avi - Mean SSIM: 0.6881, Std SSIM: 0.0836\n","Speaker: M3 - File: usctimit_mri_m3_146_150_LSTM.avi - Mean SSIM: 0.7697, Std SSIM: 0.0568\n","Speaker: M3 - File: usctimit_mri_m3_261_265_LSTM.avi - Mean SSIM: 0.7577, Std SSIM: 0.0598\n","Speaker: M3 - File: usctimit_mri_m3_121_125_LSTM.avi - Mean SSIM: 0.7822, Std SSIM: 0.0542\n","Speaker: M3 - File: usctimit_mri_m3_316_320_LSTM.avi - Mean SSIM: 0.7604, Std SSIM: 0.0542\n","Speaker: M3 - File: usctimit_mri_m3_416_420_LSTM.avi - Mean SSIM: 0.7488, Std SSIM: 0.0534\n","Speaker: M3 - File: usctimit_mri_m3_101_105_LSTM.avi - Mean SSIM: 0.7625, Std SSIM: 0.0617\n","Speaker: M3 - File: usctimit_mri_m3_061_065_LSTM.avi - Mean SSIM: 0.7588, Std SSIM: 0.0580\n","Speaker: M3 - File: usctimit_mri_m3_091_095_LSTM.avi - Mean SSIM: 0.7720, Std SSIM: 0.0610\n","Speaker: M3 - File: usctimit_mri_m3_401_405_LSTM.avi - Mean SSIM: 0.7462, Std SSIM: 0.0602\n","\n","Overall SSIM Results for Each Speaker:\n","F1 - Mean SSIM: 0.8000, Std SSIM: 0.0220\n","F2 - Mean SSIM: 0.7200, Std SSIM: 0.0160\n","M2 - Mean SSIM: 0.7654, Std SSIM: 0.0229\n","M3 - Mean SSIM: 0.7546, Std SSIM: 0.0244\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tJQDthilJqPq"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"15wBYOVpN843vPXxSJMP_b5MmIjs_TRcb","timestamp":1728041980631},{"file_id":"14O59UIyWvnmVokaobP83yLhVWNyi9KH6","timestamp":1681844598338},{"file_id":"1BMA3DxqG3QD8_9PMZvohSFZy3nVeJQCV","timestamp":1681813261496},{"file_id":"1eiPqk6HYav2MW0sr_Iddfdc40Px83nIp","timestamp":1664108924401}],"gpuType":"T4","mount_file_id":"1O2AqSZCwbYYdBn68n0TH_E8qatO5SN3o","authorship_tag":"ABX9TyN5QdQ1G6uLOWkcu8lJnfRR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}